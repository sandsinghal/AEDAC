{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "task2_code.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u92SMvMGS6Nv",
        "outputId": "3e21a597-e98a-4b37-ff39-700cc07de935"
      },
      "source": [
        "!pip3 install python-levenshtein"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting python-levenshtein\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/a9/d1785c85ebf9b7dfacd08938dd028209c34a0ea3b1bcdb895208bd40a67d/python-Levenshtein-0.12.0.tar.gz (48kB)\n",
            "\r\u001b[K     |██████▊                         | 10kB 15.4MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 20kB 20.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 30kB 18.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 40kB 10.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 3.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from python-levenshtein) (50.3.2)\n",
            "Building wheels for collected packages: python-levenshtein\n",
            "  Building wheel for python-levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-levenshtein: filename=python_Levenshtein-0.12.0-cp36-cp36m-linux_x86_64.whl size=144803 sha256=40011036aa11a31f438a09489c5923c798acdaea00a06eb8dd637deb364478e3\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/c2/93/660fd5f7559049268ad2dc6d81c4e39e9e36518766eaf7e342\n",
            "Successfully built python-levenshtein\n",
            "Installing collected packages: python-levenshtein\n",
            "Successfully installed python-levenshtein-0.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iV1krbiNTD39"
      },
      "source": [
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import librosa\r\n",
        "import librosa.display\r\n",
        "import pdb\r\n",
        "import string\r\n",
        "import pandas as pd\r\n",
        "from Levenshtein import distance\r\n",
        "import scipy\r\n",
        "import os\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D, BatchNormalization\r\n",
        "from tensorflow.keras.models import model_from_json\r\n",
        "from keras.utils import to_categorical\r\n",
        "from scipy import stats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XPfbtu9THO3",
        "outputId": "a1ed4262-ccb3-4676-e0f6-c643f4915d15"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoNUUnh2q4lP"
      },
      "source": [
        "# Load the model\r\n",
        "model2 = tf.keras.models.load_model('/content/gdrive/MyDrive/EE698V/models/model_task1_40_65epochs_52')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Bv2XGo0rf4u"
      },
      "source": [
        "labl = ['air_conditioner','car_horn','children_playing','dog_bark','drilling','engine_idling','gun_shot','jackhammer','siren','street_music']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Enq7vW-5n2x7"
      },
      "source": [
        "# Load test files, loop over each, break into 40 frames, get predictions, do majority voting and check for consecutive 3 same labels, create output csv\r\n",
        "\r\n",
        "final_test_path = '/content/gdrive/MyDrive/EE698V/test_task2/feats/'\r\n",
        "save_path = '/content/gdrive/MyDrive/EE698V/test_task2/'\r\n",
        "pred_file_name = []\r\n",
        "pred_labels = []\r\n",
        "for i in os.listdir(final_test_path):\r\n",
        "  pred_file_name.append(i)\r\n",
        "  test_image = np.load(final_test_path+i)\r\n",
        "  iter = int(test_image.shape[1]/40)\r\n",
        "  empty = []\r\n",
        "  for j in range(iter):\r\n",
        "    test_file = test_image[:,40*(j):40*(j+1)]\r\n",
        "    test_file = test_file.reshape((1,)+test_file.shape + (1,))\r\n",
        "    empty.append(np.argmax(model2.predict(test_file)))\r\n",
        "  \r\n",
        "  empty2 = []\r\n",
        "  for count,pr in enumerate(empty):\r\n",
        "    if count == 0 or count == len(empty)-1:\r\n",
        "      continue\r\n",
        "    if empty[count-1] == pr and empty[count+1] == pr:\r\n",
        "      empty2.append(pr)\r\n",
        "\r\n",
        "  empty3 = []\r\n",
        "  empty3.append(empty2[0])\r\n",
        "  for pr in empty2:\r\n",
        "    if pr == empty3[-1]:\r\n",
        "      continue\r\n",
        "    else:\r\n",
        "      empty3.append(pr)\r\n",
        "\r\n",
        "  empty3 = np.array(empty3)\r\n",
        "\r\n",
        "  final_string = ''\r\n",
        "  for count,pr in enumerate(empty3):\r\n",
        "    if count == empty3.size -1:\r\n",
        "      final_string += labl[pr]\r\n",
        "    else:\r\n",
        "      final_string += labl[pr] + '-'\r\n",
        "\r\n",
        "  pred_labels.append(final_string)\r\n",
        "\r\n",
        "df = pd.DataFrame()\r\n",
        "df['slice_file_name'] = pred_file_name\r\n",
        "df['class'] = pred_labels\r\n",
        "df.to_csv(save_path + 'task2_labels_test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}