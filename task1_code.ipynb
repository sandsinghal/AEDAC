{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "task1_code.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u92SMvMGS6Nv",
        "outputId": "3e21a597-e98a-4b37-ff39-700cc07de935"
      },
      "source": [
        "!pip3 install python-levenshtein"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting python-levenshtein\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/a9/d1785c85ebf9b7dfacd08938dd028209c34a0ea3b1bcdb895208bd40a67d/python-Levenshtein-0.12.0.tar.gz (48kB)\n",
            "\r\u001b[K     |██████▊                         | 10kB 15.4MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 20kB 20.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 30kB 18.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 40kB 10.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 3.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from python-levenshtein) (50.3.2)\n",
            "Building wheels for collected packages: python-levenshtein\n",
            "  Building wheel for python-levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-levenshtein: filename=python_Levenshtein-0.12.0-cp36-cp36m-linux_x86_64.whl size=144803 sha256=40011036aa11a31f438a09489c5923c798acdaea00a06eb8dd637deb364478e3\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/c2/93/660fd5f7559049268ad2dc6d81c4e39e9e36518766eaf7e342\n",
            "Successfully built python-levenshtein\n",
            "Installing collected packages: python-levenshtein\n",
            "Successfully installed python-levenshtein-0.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iV1krbiNTD39"
      },
      "source": [
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import librosa\r\n",
        "import librosa.display\r\n",
        "import pdb\r\n",
        "import string\r\n",
        "import pandas as pd\r\n",
        "from Levenshtein import distance\r\n",
        "import scipy\r\n",
        "import os\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D, BatchNormalization\r\n",
        "from tensorflow.keras.models import model_from_json\r\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XPfbtu9THO3",
        "outputId": "a1ed4262-ccb3-4676-e0f6-c643f4915d15"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-D0yiWLTJTl"
      },
      "source": [
        "def wav2feat(wavfile):\r\n",
        "    '''\r\n",
        "    Input: audio wav file name\r\n",
        "    Output: Magnitude spectrogram\r\n",
        "    '''\r\n",
        "    x, Fs = librosa.load(wavfile, sr=44100, mono=True) \r\n",
        "    hop = int(0.01 * Fs) # 10ms\r\n",
        "    win = int(0.02 * Fs) # 20ms\r\n",
        "    X = librosa.stft(x, n_fft=1024, hop_length=hop, win_length=win, window='hann', center=True, pad_mode='reflect')\r\n",
        "    return np.abs(X), Fs\r\n",
        "\r\n",
        "def wavs2feat(wavfiles):\r\n",
        "    '''\r\n",
        "    Concatenate the audio files listed in wavfiles\r\n",
        "    Input: list of audio wav file names\r\n",
        "    Output: Magnitude spectrogram of concatenated wav\r\n",
        "    '''\r\n",
        "    x = []\r\n",
        "    for wf in wavfiles:\r\n",
        "        x1, Fs = librosa.load(wf, sr=44100, mono=True)\r\n",
        "        x.append(x1)\r\n",
        "    x = np.hstack(x)\r\n",
        "    hop = int(0.01 * Fs) # 10ms\r\n",
        "    win = int(0.02 * Fs) # 20ms\r\n",
        "    X = librosa.stft(x, n_fft=1024, hop_length=hop, win_length=win, window='hann', center=True, pad_mode='reflect')\r\n",
        "    return np.abs(X), Fs\r\n",
        "\r\n",
        "def read_csv(filename):\r\n",
        "    id_label = {}\r\n",
        "    with open(filename,'r') as fid:\r\n",
        "        for line in fid: # '176787-5-0-27.wav,engine_idling\\n'\r\n",
        "            tokens = line.strip().split(',') # ['176787-5-0-27.wav', 'engine_idling']\r\n",
        "            id_label[tokens[0]] = tokens[1]\r\n",
        "    return id_label\r\n",
        "\r\n",
        "def editDistance(gt, est):\r\n",
        "    '''both are lists of labels\r\n",
        "    E.g. gt is \"dog_bark-street_music-engine_idling\"\r\n",
        "    E.g. est is \"street_music-engine_idling\"\r\n",
        "    '''\r\n",
        "    gttokens = gt.split('-')\r\n",
        "    esttokens = est.split('-')\r\n",
        "    # Map token to char\r\n",
        "    tokenset = list(set(gttokens+esttokens)) # ['dog_bark', 'siren', 'street_music', 'engine_idling']\r\n",
        "    token_char = {}\r\n",
        "    for i in range(len(tokenset)):\r\n",
        "        token_char[tokenset[i]] = string.ascii_uppercase[i]  # {'dog_bark': 'A', 'siren': 'B', 'street_music': 'C', 'engine_idling': 'D'}\r\n",
        "    # convert gt and est to strings\r\n",
        "    gtstr = [token_char[t] for t in gttokens]\r\n",
        "    gtstr = ''.join(gtstr)  # 'BCA'\r\n",
        "    eststr = [token_char[t] for t in esttokens]\r\n",
        "    eststr = ''.join(eststr)  # \r\n",
        "    # Compare\r\n",
        "    editdist = distance(gtstr, eststr) # 1\r\n",
        "    score = 1 - editdist/len(gtstr)\r\n",
        "    return editdist, score\r\n",
        "\r\n",
        "def evals(gtcsv, estcsv, taskid):\r\n",
        "    gt_id_label = read_csv(gtcsv)\r\n",
        "    est_id_label = read_csv(estcsv)\r\n",
        "    score = 0\r\n",
        "    for id in est_id_label:\r\n",
        "        if taskid==1:\r\n",
        "            if est_id_label[id] == gt_id_label[id]:\r\n",
        "                score += 1\r\n",
        "        elif taskid==2:\r\n",
        "            _, ss = editDistance(gt_id_label[id], est_id_label[id])\r\n",
        "            score += ss\r\n",
        "        else:\r\n",
        "            pdb.set_trace()\r\n",
        "            assert False, [\"taskid not correct; it is\", taskid]\r\n",
        "    avgScore = score/len(est_id_label)\r\n",
        "    return avgScore\r\n",
        "\r\n",
        "# if __name__==\"__main__\":\r\n",
        "#     wavs = '/content/gdrive/MyDrive/EE698V/shared_train/audio_train/180126-4-4-2.wav'\r\n",
        "#     x, Fs= wav2feat(wavs)\r\n",
        "#     print(np.shape(x))\r\n",
        "#     db = librosa.amplitude_to_db(x,ref=np.max)\r\n",
        "#     a = librosa.display.specshow(db, sr=Fs, y_axis='log', x_axis='time')\r\n",
        "\r\n",
        "#     # wavfiles = ['../shared_train/audio_train/180937-7-3-27.wav','../shared_train/audio_train/180937-7-3-27.wav']\r\n",
        "#     # X = wavs2feat(wavfiles)\r\n",
        "#     # eval('test_task1/labels.csv', 'test_task1/est.csv', 1)\r\n",
        "#     editDistance(\"dog_bark-street_music-engine_idling\",\r\n",
        "#         \"siren-street_music-engine_idling\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02WIVt4Xnxg0"
      },
      "source": [
        "# Remove exact same audio samples from dataset\r\n",
        "list_of_files = os.listdir('/content/gdrive/MyDrive/EE698V/shared_train/audio_train_1ch/')\r\n",
        "final_list = []\r\n",
        "seen = set()\r\n",
        "for i in list_of_files:\r\n",
        "  if i.split('-')[0] in seen:\r\n",
        "    continue:\r\n",
        "  else:\r\n",
        "    seen.add(i.split('-')[0])\r\n",
        "    final_list.append(i)\r\n",
        "\r\n",
        "final_list = np.array(final_list)\r\n",
        "with open('/content/gdrive/MyDrive/EE698V/train_label/unique_files','wb') as f:\r\n",
        "  np.save(f,final_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h49ozBxgVhES"
      },
      "source": [
        "# Load unique audio samples\r\n",
        "with open('/content/gdrive/MyDrive/EE698V/train_label/unique_files','rb') as f:\r\n",
        "  files_list = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fl-2qNeGWAjp",
        "outputId": "a45c28c3-378e-49ed-8da6-b480f4480337"
      },
      "source": [
        "# Get spectrogam of audios and create training array of them\r\n",
        "train_images = []\r\n",
        "train_labels = np.array([])\r\n",
        "file_path = '/content/gdrive/MyDrive/EE698V/shared_train/audio_train_1ch/'\r\n",
        "i=1\r\n",
        "for wavs in files_list:\r\n",
        "  x, Fs= wav2feat(file_path + wavs)\r\n",
        "  labl = int(wavs.split('-')[1])\r\n",
        "  if i%100==0:\r\n",
        "    print(i)\r\n",
        "  i+=1\r\n",
        "  train_images.append(np.array(x))\r\n",
        "  train_labels = np.append(train_labels,labl)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100\n",
            "200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MP_RzRxTot4"
      },
      "source": [
        "# Break each audio spectrogram into 40 frames each and put in a new array \r\n",
        "train_images2 = []\r\n",
        "train_labels2 = []\r\n",
        "for labl,i in enumerate(train_images):\r\n",
        "  iter = int(i.shape[1]/40)\r\n",
        "  for j in range(iter):\r\n",
        "    train_images2.append(i[:,40*(j):40*(j+1)])\r\n",
        "    train_labels2.append(train_labels[labl])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMFtyaNFUaA1"
      },
      "source": [
        "# Reshape the array and one hot encode the labels for sending to network\r\n",
        "train_images = np.array(train_images2)\r\n",
        "train_images = train_images.reshape(train_images.shape+(1,))\r\n",
        "\r\n",
        "train_labels = np.array(train_labels2)\r\n",
        "train_labels = train_labels.astype(int)\r\n",
        "train_labels = to_categorical(train_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEZTY0SlYa3l",
        "outputId": "8c74d13c-77d0-4112-a451-371d6f9f8fea"
      },
      "source": [
        "# Re confirm the shapes before starting the training\r\n",
        "print(train_images.shape)\r\n",
        "print(train_labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1984, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqSN8-4rbb-U",
        "outputId": "121657f2-36a2-4082-caf9-2ff80c61b9c9"
      },
      "source": [
        "# Validation data taken from other sources\r\n",
        "if __name__==\"__main__\":\r\n",
        "  testu_images = []\r\n",
        "  testu_labels = []\r\n",
        "  file_path = '/content/gdrive/MyDrive/EE698V/Test_Validation/'\r\n",
        "  i = 1\r\n",
        "  for wavs in os.listdir(file_path):\r\n",
        "    if(i==300):\r\n",
        "      break\r\n",
        "    x, Fs= wav2feat(file_path + wavs)\r\n",
        "    labl = int(wavs.split('-')[1])\r\n",
        "    if i%100==0:\r\n",
        "      print(i)\r\n",
        "    i+=1\r\n",
        "    testu_images.append(np.array(x))\r\n",
        "    testu_labels.append(labl)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100\n",
            "200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUu24wlcbbW7"
      },
      "source": [
        "testu_images2 = []\r\n",
        "testu_labels2 = []\r\n",
        "for labl,i in enumerate(testu_images):\r\n",
        "  iter = int(i.shape[1]/40)\r\n",
        "  for j in range(iter):\r\n",
        "    if(j==10):\r\n",
        "      break\r\n",
        "    testu_images2.append(i[:,40*(j):40*(j+1)])\r\n",
        "    testu_labels2.append(testu_labels[labl])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62vTcRsVcMX0"
      },
      "source": [
        "testu_images = np.array(testu_images2)\r\n",
        "testu_images = testu_images.reshape(testu_images.shape+(1,))\r\n",
        "\r\n",
        "testu_labels = np.array(testu_labels2)\r\n",
        "testu_labels = testu_labels.astype(int)\r\n",
        "testu_labels = to_categorical(testu_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pzb01LuKdNZP",
        "outputId": "43fe3c0b-599e-4b44-b878-8adc01cb2ac5"
      },
      "source": [
        "testu_images.shape\r\n",
        "#testu_labels.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2794, 513, 40, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYpgftAGddxp"
      },
      "source": [
        "# To avoid repeated processing and trying models quickly save above arrays\r\n",
        "\r\n",
        "with open('/content/gdrive/MyDrive/EE698V/train_label/train_label_task1_40.npy','wb') as f:\r\n",
        "  np.save(f,train_labels)\r\n",
        "with open('/content/gdrive/MyDrive/EE698V/train_label/train_images_task1_40.npy','wb') as f:\r\n",
        "  np.save(f,train_images)\r\n",
        "with open('/content/gdrive/MyDrive/EE698V/train_label/testu_images_task1_40.npy','wb') as f:\r\n",
        "  np.save(f,testu_images)\r\n",
        "with open('/content/gdrive/MyDrive/EE698V/train_label/testu_labels_task1_40.npy','wb') as f:\r\n",
        "  np.save(f,testu_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7rk7TvmnMip"
      },
      "source": [
        "# Load directly and start training\r\n",
        "\r\n",
        "with open('/content/gdrive/MyDrive/EE698V/train_label/train_label_task1_40.npy','rb') as f:\r\n",
        "  train_labels = np.load(f)\r\n",
        "with open('/content/gdrive/MyDrive/EE698V/train_label/train_images_task1_40.npy','rb') as f:\r\n",
        "  train_images = np.load(f)\r\n",
        "with open('/content/gdrive/MyDrive/EE698V/train_label/testu_images_task1_40.npy','rb') as f:\r\n",
        "  testu_images = np.load(f)\r\n",
        "with open('/content/gdrive/MyDrive/EE698V/train_label/testu_labels_task1_40.npy','rb') as f:\r\n",
        "  testu_labels = np.load(f)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KjINZ4KDSfL"
      },
      "source": [
        "print(train_labels.shape)\n",
        "print(train_images.shape)\n",
        "print(testu_images.shape)\n",
        "print(testu_labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTxrmh_rUy_f",
        "outputId": "77412a03-5f64-4b79-bcce-bf5eec364dcb"
      },
      "source": [
        "# Final Model\r\n",
        "\r\n",
        "model2 = Sequential()\r\n",
        "\r\n",
        "model2.add(Conv2D(16,kernel_size=(3,3),activation='relu',input_shape=(513, 40, 1)))\r\n",
        "model2.add(BatchNormalization())\r\n",
        "model2.add(MaxPooling2D(pool_size=(4,1)))\r\n",
        "\r\n",
        "model2.add(Conv2D(16,kernel_size=(3,3),activation='relu'))\r\n",
        "model2.add(BatchNormalization())\r\n",
        "model2.add(MaxPooling2D(pool_size=(4,2)))\r\n",
        "\r\n",
        "model2.add(Conv2D(16,kernel_size=(3,3),activation='relu'))\r\n",
        "model2.add(BatchNormalization())\r\n",
        "model2.add(MaxPooling2D(pool_size=(4,2)))\r\n",
        "\r\n",
        "model2.add(Dropout(0.8))\r\n",
        "model2.add(Flatten())\r\n",
        "\r\n",
        "model2.add(Dense(128,activation='relu'))\r\n",
        "model2.add(Dropout(0.5))\r\n",
        "# model2.add(Dense(64,activation='relu'))\r\n",
        "# model2.add(Dropout(0.5))\r\n",
        "model2.add(Dense(10,activation='softmax'))\r\n",
        "\r\n",
        "model2.compile(loss=tf.keras.losses.categorical_crossentropy,optimizer=tf.keras.optimizers.Adam(),metrics=['accuracy'])\r\n",
        "print(model2.summary())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_9 (Conv2D)            (None, 511, 38, 16)       160       \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 511, 38, 16)       64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 127, 38, 16)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 125, 36, 16)       2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 125, 36, 16)       64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 31, 18, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 29, 16, 16)        2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 29, 16, 16)        64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 7, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 7, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 896)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               114816    \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 121,098\n",
            "Trainable params: 121,002\n",
            "Non-trainable params: 96\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEh7QS2-azuN"
      },
      "source": [
        "# Fit the model 65 epochs\r\n",
        "model2.fit(train_images, train_labels,validation_data=(testu_images,testu_labels), batch_size=4, epochs=65, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJ0DiS7ZCakY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2874b80b-fed8-47d3-f927-3ed98456c509"
      },
      "source": [
        "# Save the model\r\n",
        "model2.save('/content/gdrive/MyDrive/EE698V/models/model_task1_40_65epochs_52')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/gdrive/MyDrive/EE698V/models/model_task1_40_65+nepochs_57/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoNUUnh2q4lP"
      },
      "source": [
        "# Load the model\r\n",
        "model2 = tf.keras.models.load_model('/content/gdrive/MyDrive/EE698V/models/model_task1_40_65epochs_52')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14YjG1uaKvMe"
      },
      "source": [
        "from scipy import stats"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Bv2XGo0rf4u"
      },
      "source": [
        "labl = ['air_conditioner','car_horn','children_playing','dog_bark','drilling','engine_idling','gun_shot','jackhammer','siren','street_music']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8p2tblSl2x7"
      },
      "source": [
        "# Load the task 1 test files, process them, generate outlabels, create csv file\r\n",
        "final_test_path = '/content/gdrive/MyDrive/EE698V/test_task1/feats/'\r\n",
        "save_path = '/content/gdrive/MyDrive/EE698V/test_task1/'\r\n",
        "pred_file_name = []\r\n",
        "pred_labels = []\r\n",
        "for i in os.listdir(final_test_path):\r\n",
        "  pred_file_name.append(i)\r\n",
        "  test_image = np.load(final_test_path+i)\r\n",
        "  iter = int(test_image.shape[1]/40)\r\n",
        "  empty = []\r\n",
        "  for j in range(iter):\r\n",
        "    test_file = test_image[:,40*(j):40*(j+1)]\r\n",
        "    test_file = test_file.reshape((1,)+test_file.shape + (1,))\r\n",
        "    empty.append(np.argmax(model2.predict(test_file)))\r\n",
        "  empty = np.array(empty)\r\n",
        "  # print(empty,stats.mode(empty),sep='\\t')\r\n",
        "  pred_labels.append(labl[stats.mode(empty)[0][0]])\r\n",
        "df = pd.DataFrame()\r\n",
        "df['slice_file_name'] = pred_file_name\r\n",
        "df['class'] = pred_labels\r\n",
        "df.to_csv(save_path + 'task1_labels_test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S77xLcHbuVGc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}